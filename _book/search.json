[{"path":"index.html","id":"prefacio","chapter":"Prefacio","heading":"Prefacio","text":"Estas notas tienen el objetivo de proporcionar una introducción práctica al uso del software estadístico R, por medio de la interfaz gráfica RStudio.Las notas fueron elaboradas como recurso de apoyo en el marco del Taller de Aplicación de técnicas estadísticas, impartido estudiantes del Posgrado en Biociencias de la Universidad de Sonora durante el semestre 2022-2, y fueron adaptadas para utilizarse en cursos de Estadística y Bioestadística durante los semestres 2023-1 y 2023-2 con estudiantes de nivel licenicatura.Cabe mencionar que para los autores, resulta muy gratificante que las notas hayan sido puestas en práctica durante el mencionado taller por los distintos asistentes en sus proyectos de tesis, los cuales abarcan una amplia gama de temas en el área de Biociencias en problemáticas de gran relevancia e impacto regional, como estudios relativos la dinámica y productividad de la flora y fauna en los distintos ecosistemas que se pueden encontrar en el estado de Sonora, desde las zonas desérticas las costeras.Los autores pretenden seguir enriqueciendo el texto con el uso subsecuente de las notas, y se espera que este trabajo sea una herramienta útil para los estudiantes que buscan comprender y aplicar las técnicas estadísticas en sus cursos y proyectos, propiciando la conexión entre la teoría y la práctica en esta disciplina.","code":""},{"path":"el-software.html","id":"el-software","chapter":"Capítulo 1 El software","heading":"Capítulo 1 El software","text":"Estas notas ofrecen una introducción práctica al uso del software estadístico R mediante la interfaz gráfica RStudio. Es por ésto que para un mejor entendimiento de los conceptos y comandos que aquí se exponen, se exhorta al usuario poner en práctica las instrucciones aquí documentadas.","code":""},{"path":"el-software.html","id":"r-y-rstudio","chapter":"Capítulo 1 El software","heading":"1.1 R y RStudio","text":"El software R es tanto un entorno de programación, como un lenguaje de programación, diseñado para hacer análisis estadístico. Es de código abierto, gratuito y multiplataforma, características que lo han convertido en una herramienta ampliamente utilizada en el campo de la estadística y el análisis de datos.Por otro lado, RStudio es un entorno de desarrollo integrado (IDE) para trabajar con el lenguaje de programación R. Es una plataforma amigable para el usuario, y entre otras propiedades, facilita la escritura de código, visualización, generación de informes reproducibles y la exportación de resultados en diversos formatos.El entorno RStudio, puede utilizarse de manera gratuita ingresando través de una cuenta en Posit https://posit.co/ o mediante la instalación previa de R y RStudio en gran variedad de sistemas operativos.Para instalar R, podemos ingresar la página https://www.r-project.org y descargar e instalar la última versión del software.continuación, para instalar RStudio, ingresamos la página https://www.posit.co y descargamos e instalamos la interfaz gráfica RStudio.","code":""},{"path":"el-software.html","id":"rscripts","chapter":"Capítulo 1 El software","heading":"1.2 RScripts","text":"Un Rscript es un archivo de texto compuesto de una serie de comandos e instrucciones escritos en el lenguaje de programación R, que al ser ejecutados realizan tareas específicas como leer y manipular datos, realizar análisis estadísticos o generar gráficos.Una vez instalado RStudio, podemos abrir un RScript nuevo para escribir y documentar la secuencia de comandos que nos permitirá realizar alguna tarea determinada. Una buena práctica es incluir comentarios en este documento que describan lo que hace cada comando, y que nos permita documentar el código y facilitar su comprensión.Los Rscripts permiten la reproducibilidad de los análisis resultantes, pues al guardar y compartir un Rscript con otros usuarios, éstos pueden ejecutar los mismos comandos para obtener resultados idénticos.","code":""},{"path":"el-software.html","id":"librería-del-usuario","chapter":"Capítulo 1 El software","heading":"1.3 Librería del usuario","text":"Al instalar el software R, se instala automáticamente una colección de paquetes del sistema base, que se almacenan en una librería. Estos paquetes se componen de funciones básicas del sistema que nos permiten realizar tareas comunes para la manipulación y el análisis de datos.Adicionalmente, podemos instalar paquetes que nos permiten extender la funcionalidad del sistema base de R. Por ejemplo, podemos ampliar la capacidad de R para la generación de gráficos más atractivos, o para el análisis de datos en áreas especializadas como el estudio de series temporales, o para realizar análisis espaciales con el manejo de datos geoespaciales.En el repositorio centralizado CRAN (Comprehensive R Archive Network) se albergan miles de paquetes creados por la comunidad de usuarios de R, disponibles para su descarga.Para utilizar un paquete en R, primero debemos instalarlo y luego cargarlo en la sesión. Una vez cargado, podremos acceder las funciones y capacidades que proporciona. lo largo de este texto se explica el uso de una gran variedad de paquetes especializados para ejecutar ciertas tareas.","code":""},{"path":"el-software.html","id":"datasets-integrados","chapter":"Capítulo 1 El software","heading":"1.4 Datasets integrados","text":"Existen algunos conjuntos de datos que se incluyen como parte de la instalación del sistema base de R, que se denominan datasets, los cuales son proporcionados por los desarrolladores del software y están disponibles para que los usuarios los utilicen directamente en su sesión, sin necesidad de descargar o importar datos desde fuentes externas.Los datasets integrados en el sistema base de R son útiles para realizar ejemplos y pruebas, así como para aprender y practicar análisis de datos en R.En estas notas se muestra el uso de algunas técnicas estadísticas aplicadas en datasets cargados en el sistema base de R.","code":""},{"path":"tipos-de-datos-y-objetos-en-r.html","id":"tipos-de-datos-y-objetos-en-r","chapter":"Capítulo 2 Tipos de datos y objetos en R","heading":"Capítulo 2 Tipos de datos y objetos en R","text":"R es un lenguaje de programación orientado objetos, lo que significa que se centra en la manipulación de objetos y datos. Estos objetos nos permiten almacenar y manipular información.Por ejemplo, en una variable podemos almacenar datos, los cuales pueden ser de distintos tipos como cadenas de caracteres, números enteros, números decimales, números complejos y valores lógicos (verdadero o falso).Por otro lado, las funciones en R, son objetos que nos permiten manipular información para realizar operaciones específicas. Las funciones pueden tomar argumentos o parámetros que determinan cómo se ejecutan esas operaciones. Las funciones en R pueden ser funciones propias del lenguaje, o funciones definidas por el mismo usuario.Se describen continuación algunos otros objetos comunmente utilizados en R.","code":""},{"path":"tipos-de-datos-y-objetos-en-r.html","id":"vectores","chapter":"Capítulo 2 Tipos de datos y objetos en R","heading":"2.1 Vectores","text":"Los vectores son una de las estructuras de datos más fundamentales en R. Un vector es una secuencia ordenada de elementos del mismo tipo, y pueden ser de tipo numérico, de caracteres, lógicos u otros tipos.Por ejemplo, (0,1, 2, 3, 25, 23) es un vector numérico, que puede ser creado utilizando la función c() del sistema base de R la cual concatena elementos, y puede ser almacenado en la variable x mediante el símbolo de asignación <-:Podemos utilizar otras funciones para examinar distintas características de los objetos que creamos o que importamos. Por ejemplo, para verificar el tipo de objeto que almacenamos en la variable x podemos usar la función class(),que indica que x es un vector numérico. Si además queremos investigar el tipo de datos que componen al objeto x, utilizamos la función typeof(),que nos indica que los elementos numéricos son de hecho valores reales.Otras características que podemos examinar es la longitud del vector,o incluso podemos efectuar operaciones con los elementos almacenados en él, como por ejemplo, podemos sumar sus entradas con el comando sum()Otros ejemplos de vectores son:Podemos también crear nuevos vectores partir de otros dados, por ejemplo utilizando la función rep()instrucción con la que se ha concatenado 4 veces el vector y.","code":"\nx <- c(0, 1, 2, 3, 25, 23)\nx## [1]  0  1  2  3 25 23\nclass(x)## [1] \"numeric\"\ntypeof(x)## [1] \"double\"\nlength(x)## [1] 6\nsum(x)## [1] 54\ny <- c(\"A\", \"B\", \"C\") # vector de caracteres\n\nz <- c(T, T, F, F) # vector de elementos lógicos\n\nw <- c(5:9) # vector numérico con elementos enteros sucesivos del 5 al 9\nrep(y, times = 4)##  [1] \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\" \"C\""},{"path":"tipos-de-datos-y-objetos-en-r.html","id":"matrices","chapter":"Capítulo 2 Tipos de datos y objetos en R","heading":"2.2 Matrices","text":"Las matrices son estructuras bidimensionales en la que los datos están organizados en renglones y columnas. Todas las entradas de una matriz deben constar de elementos del mismo tipo de datos.Por ejemplo, podemos manipular vectores para crear una matriz. Con la función cbind(), se pueden unir dos vectores para formar las columnas de una matrizo combinar por filas los vectores utilizando la función rbind().","code":"\nvec1 <- c(1, 2, 3, 4, 5)\nvec2 <- c(-1, -2, -3, -4, -5)\ncbind(Columna_1 = vec1, Columna_2= vec2)##      Columna_1 Columna_2\n## [1,]         1        -1\n## [2,]         2        -2\n## [3,]         3        -3\n## [4,]         4        -4\n## [5,]         5        -5\nrbind(Renglon_1 = vec1,Renglon_2 = vec2)##           [,1] [,2] [,3] [,4] [,5]\n## Renglon_1    1    2    3    4    5\n## Renglon_2   -1   -2   -3   -4   -5"},{"path":"tipos-de-datos-y-objetos-en-r.html","id":"dataframes","chapter":"Capítulo 2 Tipos de datos y objetos en R","heading":"2.3 Dataframes","text":"Un data frame es una estructura bidimensional que se utiliza generalmente para almacenar datos tabulares. Cada columna de un data frame puede ser de un tipo diferente.Los data frames son similares las tablas de una base de datos u hojas de cálculo, donde las columnas representan variables, y los renglones corresponden observaciones.Existen algunos comandos que son especialmente útiles para indagar el contenido de una base de datos, especialmente cuando éstas son de gran tamaño.\nPor ejemplo, supongamos que tenemos los tratamientos 1, 2 y 3, y que para cada uno de los tratamientos se utilizaron distintas unidades experimentales sobre las cuales se tomó una medición:Podemos analizar la estructura de la tabla utilizando la función str(),que nos indica las características generales del dataframe, esto es, su tamaño, los nombres de las columnas, y el tipo de datos almacenados en cada columna.Puede también ser útil visualizar los primeros renglones de la tabla, lo que podemos solicitar utilizando la función head(),y de manera similar, para visualizar lo últimos tres renglones, podmeos utilizar la función tail()Al conocer el tipo de contenido de las bases de datos, tendremos un mejor entendiemiento de cómo manipular la información para realizar análisis más específicos.","code":"\n# Almacenamos los datos en dos columnas\ndatos <- data.frame(Tratamiento = rep(c(\"1\", \"2\", \"3\"), 6), \n                    Tiempo = c(14, 16, 13, \n                               24, 25, 21, \n                               18, 19, 14, \n                               12, 16, 17, \n                               23, 22, 21, \n                               25, 23, 22)\n                    )\ndatos##    Tratamiento Tiempo\n## 1            1     14\n## 2            2     16\n## 3            3     13\n## 4            1     24\n## 5            2     25\n## 6            3     21\n## 7            1     18\n## 8            2     19\n## 9            3     14\n## 10           1     12\n## 11           2     16\n## 12           3     17\n## 13           1     23\n## 14           2     22\n## 15           3     21\n## 16           1     25\n## 17           2     23\n## 18           3     22\nstr(datos)## 'data.frame':    18 obs. of  2 variables:\n##  $ Tratamiento: chr  \"1\" \"2\" \"3\" \"1\" ...\n##  $ Tiempo     : num  14 16 13 24 25 21 18 19 14 12 ...\n# Imprimir los primeros tres renglones del dataframe\nhead(datos,3)##   Tratamiento Tiempo\n## 1           1     14\n## 2           2     16\n## 3           3     13\n# Imprimir los últimos tres renglones\ntail(datos,3)##    Tratamiento Tiempo\n## 16           1     25\n## 17           2     23\n## 18           3     22"},{"path":"lectura-de-archivos.html","id":"lectura-de-archivos","chapter":"Capítulo 3 Lectura de archivos","heading":"Capítulo 3 Lectura de archivos","text":"En R podemos importar una gran variedad de tipos de archivos, utilizando funciones propias del sistema base o funciones de otros paquetes.Para leer bases de datos desde un archivo en nuestra computadora, debemos cuidar que éste se encuentre almacenado en el directorio de trabajo.continuación se describé cómo importar datos desde formatos de archivos más comunmente utilizados.","code":""},{"path":"lectura-de-archivos.html","id":"archivos-de-texto","chapter":"Capítulo 3 Lectura de archivos","heading":"3.1 Archivos de texto","text":"Para leer archivos en formato TXT (texto plano) podemos usar la función read.delim():","code":"\nDatostxt <- read.delim(\"analgesics.txt\")\nhead(Datostxt)##   Pain_level Drug\n## 1          4    A\n## 2          5    A\n## 3          4    A\n## 4          3    A\n## 5          2    A\n## 6          4    A"},{"path":"lectura-de-archivos.html","id":"archivos-csv","chapter":"Capítulo 3 Lectura de archivos","heading":"3.2 Archivos csv","text":"Para leer archivos en formato CSV (valores separados por comas) podemos utilizar la función read.csv,","code":"\nDatoscsv <- read.csv(\"calificaciones.csv\", header = T)\nhead(Datoscsv)##   X  id female race ses schtyp prog read write math science socst\n## 1 1  70      0    4   1      1    1   57    52   41      47    57\n## 2 2 121      1    4   2      1    3   68    59   53      63    61\n## 3 3  86      0    4   3      1    1   44    33   54      58    31\n## 4 4 141      0    4   3      1    3   63    44   47      53    56\n## 5 5 172      0    4   2      1    2   47    52   57      53    61\n## 6 6 113      0    4   2      1    2   44    52   51      63    61"},{"path":"lectura-de-archivos.html","id":"archivos-de-excel","chapter":"Capítulo 3 Lectura de archivos","heading":"3.3 Archivos de Excel","text":"Para importar datos desde archivos de Excel, en formato XLSX (valores separados por tabulaciones) podemos utilizar la función read_xlsx del paquete readxl, que debemos agregar la librería de usuario.Para ésto descargamos primero el paquete, utilizando la función install.packages(), y continuación lo cargamos la sesión, para poder utilizar las funciones que contiene, utilizando el comando library():y posteriormente, leemos los datos,Para cada tipo de archivo, es posible encontrar funciones o paquetes específicos que facilitan su importación y el procesamiento de datos.","code":"\n# Instalación del paquete readxl\n# install.packages(\"readxl\")\n\n# Carga del paquete en la sesión de trabajo\nlibrary(readxl)\nDatosXlsx <- read_xlsx(\"Resultados.xlsx\")## New names:\n## • `` -> `...1`\nhead(DatosXlsx)## # A tibble: 6 × 12\n##    ...1    id female  race   ses schtyp  prog  read write  math science socst\n##   <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl> <dbl>\n## 1     1    70      0     4     1      1     1    57    52    41      47    57\n## 2     2   121      1     4     2      1     3    68    59    53      63    61\n## 3     3    86      0     4     3      1     1    44    33    54      58    31\n## 4     4   141      0     4     3      1     3    63    44    47      53    56\n## 5     5   172      0     4     2      1     2    47    52    57      53    61\n## 6     6   113      0     4     2      1     2    44    52    51      63    61"},{"path":"análisis-exploratorio-de-datos.html","id":"análisis-exploratorio-de-datos","chapter":"Capítulo 4 Análisis exploratorio de datos","heading":"Capítulo 4 Análisis exploratorio de datos","text":"Para comprender el comportamiento de un conjunto de datos, antes de aplicar técnicas más especializadas de la estadística, se suele realizar en primer lugar un análisis exploratprio de datos, con el objetivo de visualizar y comprender la distribución de los datos.","code":""},{"path":"análisis-exploratorio-de-datos.html","id":"ejemplo-1","chapter":"Capítulo 4 Análisis exploratorio de datos","heading":"4.1 Ejemplo 1","text":"Supongamos que registramos la cantidad de respuestas correctas logradas en un exámen, aplicado un grupo de 15 estudiantes:podemos crear una tabla de frecuencias absolutas con la siguiente instrucción:y elaborar una gráfica sencilla, pero de gran utilidad como lo es un diagrama de barrasAdemás, podemos calcular fácilmente algunas medidas descriptivas. Por ejemplo, podemos examinar el valor mínimo y máximo ordenando las observaciones como sigue:calcular la media,la mediana,la varianza,la desviación estándar,los cuartiles,especificar otros cuantiles deseadoso podemos solicitar un resumen de las estadísticas descriptivas anteriores con la función summary(),","code":"\nrespuestas <- c(2, 4, 4, 3, 5, 5, 6, 3, 7, 8, 3, 4, 5, 5, 4)\ntable(respuestas)## respuestas\n## 2 3 4 5 6 7 8 \n## 1 3 4 4 1 1 1\nbarplot(table(respuestas), \n        main = \"Número de respuestas correctas\", \n        col = \"blue\")\nsort(respuestas)##  [1] 2 3 3 3 4 4 4 4 5 5 5 5 6 7 8\nmean(respuestas)## [1] 4.533333\nmedian(respuestas)## [1] 4\nvar(respuestas)## [1] 2.552381\nsd(respuestas)## [1] 1.597617\nquantile(respuestas)##   0%  25%  50%  75% 100% \n##  2.0  3.5  4.0  5.0  8.0\nquantile(respuestas, c(0.1,0.5,0.9))## 10% 50% 90% \n## 3.0 4.0 6.6\nsummary(respuestas)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   2.000   3.500   4.000   4.533   5.000   8.000"},{"path":"análisis-exploratorio-de-datos.html","id":"ejemplo-2","chapter":"Capítulo 4 Análisis exploratorio de datos","heading":"4.2 Ejemplo 2","text":"Consideremos ahora otro conjunto de datos,Otra herramienta visual de la estadística descriptiva que podemos realizar en un conjunto de datos para analizar su distribución, es la construcción de un diagrma de tallo y hojas. Para elaborarlo, primero ordenamos los datos,y graficamos el diagrama con los datos ordenadoso podemos elaborar también un diagrama de caja,","code":"\ndatos2 <- c(2.4, 2.6, 1.3, 2.7, 3.1, 3.4, 3.6, 2.5, 3.7, \n            3.9, 4.2, 4.1, 4.5, 5.2, 3.3, 1.6, 3.7,7.6)\nsort(datos2)##  [1] 1.3 1.6 2.4 2.5 2.6 2.7 3.1 3.3 3.4 3.6 3.7 3.7 3.9 4.1 4.2 4.5 5.2 7.6\nstem(datos2, scale=2)## \n##   The decimal point is at the |\n## \n##   1 | 36\n##   2 | 4567\n##   3 | 1346779\n##   4 | 125\n##   5 | 2\n##   6 | \n##   7 | 6\nboxplot(datos2, horizontal = T, border = \"blue\", \n        xlab = \"Tiempos\", main = \"Diagrama de caja\")"},{"path":"análisis-exploratorio-de-datos.html","id":"ejemplo-3","chapter":"Capítulo 4 Análisis exploratorio de datos","heading":"4.3 Ejemplo 3","text":"Simulemos ahora una muestra aleatoria de 100 observaciones provenientes de una distribución normal, con media \\(\\mu = 20\\) y desviación estándar \\(\\sigma = 3\\),Podemos analizar su distribución por medio de un histograma,y personalizar la gráfica añadiendo una curva normal,","code":"\ndatos3 <- rnorm(100, 20, 3)\nhist(datos3)\nhist(datos3, freq = FALSE)\nejenorm <- seq(10, 30, 0.01)\nlines(ejenorm, dnorm(ejenorm, 20,3))"},{"path":"análisis-exploratorio-de-datos.html","id":"ejemplo-4","chapter":"Capítulo 4 Análisis exploratorio de datos","heading":"4.4 Ejemplo 4","text":"Comparemos ahora varios conjuntos de datos. Para esto, generemos dos muestras de una distribución normal, y una tercer muestra de una distribución chi cuadarada,Comparemos los datos de las primeras dos muestras mediante diagramas de cajasPodemos efectuar un gráfico cuantil-cuantil (o gráfico Q-Q), para comparar si las dos muestras x1 y x2 provienen de la misma distribuciónO podemos reemplazar una de las muestras en la comparación anterior, por los cuantiles de una distribución normal, para determinar si cada una de la muestras sigue una distribución normal. Por ejemplo, para la muestra x1 obtenemos el siguiente gráfico,y para la muestra x3 el siguiente,","code":"\nx1 <- rnorm(30, 10, 1.5)\nx2 <- rnorm(30, 15, 1)\nx3 <- rchisq(30, 4)\nboxplot(x1,x2, horizontal = TRUE)\nqqplot(x1, x2, xlim = c(4,18), ylim=c(4,18))\nqqnorm(x1, main=\"qqplot de x1\")\nqqline(x1,col=2)\nqqnorm(x3,main=\"qqplot de x3\")\nqqline(x3,col=2)"},{"path":"análisis-descriptivo-para-variables-correlacionadas.html","id":"análisis-descriptivo-para-variables-correlacionadas","chapter":"Capítulo 5 Análisis descriptivo para variables correlacionadas","heading":"Capítulo 5 Análisis descriptivo para variables correlacionadas","text":"Para comprender la relación entre dos variables y tomar decisiones sobre posibles análisis posteriores, un estudio común en estadística suele consistir en investigar si dos variables se encuentran correlacionadas. Usualmente se calcula un valor numérico de dicha correlación y se complementa el estudio con un análisis gráfico.","code":""},{"path":"análisis-descriptivo-para-variables-correlacionadas.html","id":"ejemplo-1-1","chapter":"Capítulo 5 Análisis descriptivo para variables correlacionadas","heading":"5.1 Ejemplo 1","text":"Consideremos un experimento donde se registraron datos de la edad gestacional y peso al nacer de un grupo de 17 bebés.Para comprender la relación entre estas dos variables, se puede calcular su correlación,y reforzar el resultado numérico obtenido, mediante un diagrama de dispersiónPodemos ajustar un modelo de regresión lineal, para establecer la relación lineal de una variable respecto la otra,y solicitar los detalles del modelo con la siguiente instrucción,podemos además ajustar la línea de regresión en el diagrama de dispersión,Para extraer información específica asociada al modelo, como por ejemplo sus coeficientes, podemos usar la siguiente instrucción,y analizar el comportamiento de los residuales gráficamente","code":"\nedad_ges <- c(34.7, 36,29.3, 40.1, 35.7, 42.4, 40.3, 37.3, 40.9, \n              38.3, 38.5, 41.4, 39.7, 39.7, 41.1, 38, 38.7)\n\npeso_nacer <- c(1895, 2030, 1440, 2835, 3090, 3827, 3260, 2690, \n                3885, 2920, 3430, 3657, 3685, 3345, 3260, 2680, 2005)\ncor(edad_ges,peso_nacer)## [1] 0.8197466\nplot(edad_ges,peso_nacer)\nreg1 <- lm(peso_nacer ~ edad_ges)\nsummary(reg1) ## \n## Call:\n## lm(formula = peso_nacer ~ edad_ges)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -997.12 -198.17   -6.12  224.06  657.93 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -4351.62    1319.06  -3.299  0.00487 ** \n## edad_ges      190.02      34.28   5.543 5.63e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 432.8 on 15 degrees of freedom\n## Multiple R-squared:  0.672,  Adjusted R-squared:  0.6501 \n## F-statistic: 30.73 on 1 and 15 DF,  p-value: 5.629e-05\nplot(edad_ges,peso_nacer)\nabline(reg1)\nreg1$coefficients## (Intercept)    edad_ges \n##  -4351.6240    190.0193\nplot(reg1$residuals)\nabline(h=0)"},{"path":"análisis-descriptivo-para-variables-correlacionadas.html","id":"ejemplo-2-1","chapter":"Capítulo 5 Análisis descriptivo para variables correlacionadas","heading":"5.2 Ejemplo 2","text":"manera de ilustración del uso de datasets integrados en R, y para destacar la importancia de analizar un conjunto de datos desde diferentes perspectivas, continuación se analiza el dataset Anscombre, el cual fué creado por el estadístico Francis Ascombre y publicado en 1973 en American Statistician.En primer lugar cargamos el conjunto de datos Anscombe,y podemos mostrar el contenido del datasetComo podemos observar, este dataset consta de cuatro subconjuntos de datos, con 11 pares de observaciones cada uno del tipo \\((x_i,y_i), = 1, ..., 4\\).Para poder utilizar en el análisis siguiente los nombres de las variables tal y como aparecen en la tabla, utilizamos la instrucción attach(),Como podemos ver con los siguientes cálculos, estos cuatro subconjuntos tienen propiedades estadísticas muy similares, pues si ajustamos un modelo de regresión cada subconjunto, obtenemos lo siguiente:sin embargo, al momento de representar gráficamente el comportamiento de los cuatro conjuntos de datos mediante diagramas de dispersión, podemos comprobar que difieren significativamenteEste conjunto de datos, precargado en R, es un ejemplo claro de la importancia de la visualización de datos en el análisis estadístico.","code":"\ndata(anscombe)\nanscombe##    x1 x2 x3 x4    y1   y2    y3    y4\n## 1  10 10 10  8  8.04 9.14  7.46  6.58\n## 2   8  8  8  8  6.95 8.14  6.77  5.76\n## 3  13 13 13  8  7.58 8.74 12.74  7.71\n## 4   9  9  9  8  8.81 8.77  7.11  8.84\n## 5  11 11 11  8  8.33 9.26  7.81  8.47\n## 6  14 14 14  8  9.96 8.10  8.84  7.04\n## 7   6  6  6  8  7.24 6.13  6.08  5.25\n## 8   4  4  4 19  4.26 3.10  5.39 12.50\n## 9  12 12 12  8 10.84 9.13  8.15  5.56\n## 10  7  7  7  8  4.82 7.26  6.42  7.91\n## 11  5  5  5  8  5.68 4.74  5.73  6.89\nrm(list = ls())\nattach(anscombe)\nregresion1 <- lm(y1 ~ x1)\nregresion1## \n## Call:\n## lm(formula = y1 ~ x1)\n## \n## Coefficients:\n## (Intercept)           x1  \n##      3.0001       0.5001\nregresion2 <- lm(y2 ~ x2)\nregresion2## \n## Call:\n## lm(formula = y2 ~ x2)\n## \n## Coefficients:\n## (Intercept)           x2  \n##       3.001        0.500\nregresion3 <- lm(y3~ x3)\nregresion3## \n## Call:\n## lm(formula = y3 ~ x3)\n## \n## Coefficients:\n## (Intercept)           x3  \n##      3.0025       0.4997\nregresion4 <- lm(y4~x4)\nregresion4## \n## Call:\n## lm(formula = y4 ~ x4)\n## \n## Coefficients:\n## (Intercept)           x4  \n##      3.0017       0.4999\npar(mfrow = c(2,2))\nplot(x1,y1)\nplot(x2,y2)\nplot(x3,y3)\nplot(x4,y4)"},{"path":"intervalos-de-confianza.html","id":"intervalos-de-confianza","chapter":"Capítulo 6 Intervalos de confianza","heading":"Capítulo 6 Intervalos de confianza","text":"Un intervalo de confianza es un rango de valores que se utiliza en estadística para estimar un parámetro desconocido de una población en base una muestra de datos. Comunmente el parámetro desconocido es la media, una proporción o la varianza. Su objetivo es para proporcionar una medida de la incertidumbre asociada con la estimación del parámetro en cuestión.La intención del siguiente ejercicio es comprender el significado de nivel de confianza \\(1-\\alpha\\) de un intervalo de confianza.Para ésto, se simulan continuación 25 muestras de tamaño 20 cada una, de datos provenientes de una distribución normal con media \\(\\mu = 10\\) y desviación estándar \\(\\sigma = 2\\).Para cada una de las muestras se calcula un intervalo de confianza del \\(95\\)% para la media \\(\\mu\\), utilizando un estadístico \\(t\\)-Student. Por medio de una gráfica se explora cuántos de estos intervalos capturaron el verdadero valor de \\(\\mu =10\\):y podemos detallar la información sobre los 25 intervalos,Si contamos la cantidad de veces que los intervalos capturaron el valor real \\(\\mu=10\\),y calculamos la proporción de veces que ésto ocurre,podemos ver es un valor muy cercano al 95%.","code":"\nmu <- 10 # media\nsigma <- 2 # desviación estándar\nn <- 20 # tamaño de muestra\nm <- 25 # cantidad de muestras\n\n# inicializamos vectores vacíos\npvalor <- rep(NA,m) \nresultado1 <- rep(NA,m)\nresultado2 <- rep(NA,m)\nmedias <- rep(NA,m)\n\n# Repetir m veces el procedimiento\nfor(i in 1:m)\n{\n  x <- rnorm(n,mu,sigma)\n  medias[i] <- mean(x)\n  pvalor[i] <- t.test(x, alternative = \"two.sided\", \n                      mu=10)$p.value\n  resultado1[i] <- t.test(x, alternative = \"two.sided\",\n                          mu=10)$conf.int[1]\n  resultado2[i] <- t.test(x, alternative = \"two.sided\",\n                          mu=10)$conf.int[2]\n}\n\n# Cargamos el paquete plotrix\nlibrary(plotrix)\n\n# Usamos la función plotCI() del paquete plotrix para graficar los IC\nplotCI(pvalor, medias, ui = resultado2, li = resultado1, \n       yab =\"Intervalos al 95% de confianza\")\nabline(h=mu,col=\"blue\")\nresultgral <- cbind(pvalor, resultado1,resultado2)\nresultgral##           pvalor resultado1 resultado2\n##  [1,] 0.13913537   8.420068  10.238610\n##  [2,] 0.33643119   9.563416  11.214584\n##  [3,] 0.39773871   8.552262  10.600912\n##  [4,] 0.94803660   9.153738  10.901405\n##  [5,] 0.14145178   8.500865  10.230938\n##  [6,] 0.41278647   9.548743  11.053141\n##  [7,] 0.62767587   9.329918  11.082992\n##  [8,] 0.05970467   9.968741  11.415135\n##  [9,] 0.41127483   9.337482  11.551051\n## [10,] 0.64547703   8.768019  10.782131\n## [11,] 0.97845381   9.219716  10.760143\n## [12,] 0.01891634   8.119124   9.809152\n## [13,] 0.78848433   9.090197  10.700467\n## [14,] 0.50521230   9.009777  10.505019\n## [15,] 0.82406225   8.917361  10.872114\n## [16,] 0.40012805   8.696731  10.543730\n## [17,] 0.18982763   8.689145  10.278389\n## [18,] 0.65881555   9.393072  10.938041\n## [19,] 0.89277233   9.139332  10.980867\n## [20,] 0.15061169   9.814616  11.118403\n## [21,] 0.83176861   9.314050  10.843314\n## [22,] 0.38706812   9.262526  11.818633\n## [23,] 0.12788644   9.808822  11.406101\n## [24,] 0.41223643   8.613904  10.593245\n## [25,] 0.55566405   9.477987  10.941472\ncont=0\nfor(i in 1:m)\n{\n  if(mu> resultado1[i] && mu < resultado2[i])\n    cont=cont+1\n}\ncont## [1] 24\ncont/25## [1] 0.96"},{"path":"intervalo-de-confianza-y-prueba-de-hipótesis-para-comparar-dos-medias.html","id":"intervalo-de-confianza-y-prueba-de-hipótesis-para-comparar-dos-medias","chapter":"Capítulo 7 Intervalo de confianza y prueba de hipótesis para comparar dos medias","heading":"Capítulo 7 Intervalo de confianza y prueba de hipótesis para comparar dos medias","text":"La comparación de dos medias es un procedimiento común en estadística que se utiliza cuando se desea determinar si existen diferencias significativas entre las medias de dos grupos o poblaciones. El siguiente ejercicio muestra dos enfoques para la comparación de medias, mediante intervalos de confianza y mediante pruebas de hipótesis.Para este tipo de procedimientos, debemos verificar primeramente que se cumplen los supuestos de normalidad en las muestras que se asumen independientes, y debemos verificar que sea rechazado el supuesto de homogeneidad de varianzas.Consideremos dos muestras independientes de datos:Para determinar normalidad en los conjuntos de datos, podemos aplicar la prueba de Shapiro-Wilk en cada una de éstas,Para efectuar una prueba de hipótesis para comparar las varianzas \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\), la hipótesis nula puede considerarse como \\(H_0:\\sigma_1^2 = \\sigma_2^2\\) o equivalentemente \\(H_0:\\sigma_1^2 / \\sigma_2^2 =1\\), y la hipótesis alternativa será \\(H_1:\\sigma_1^2/\\sigma_2^2 \\neq 1\\).Podemos notar que importa el orden en que se ingresa cada uno de los métodos en la prueba de homogeneidad de varianzas.El \\(p\\)-valor resultante de 0.2212 indica que hay evidencia en la muestra para rechazar la hipótesis nula.Por lo tanto, satisfechos los supuestos de normalidad y homogeneidad de varianzas, podemos solicitar el intervalo de confianza y la prueba de hipótesis para comparar las medias poblacionales utilizando el comando t.test() de R.En este caso las hipótesis que se plantean son:\n\\[\\begin{matrix}\nH_0:\\mu_1=\\mu_2\\\\\nH_1:\\mu_1\\neq \\mu_2\n\\end{matrix} \\]En este caso la muestra da evidencia para rechazar la hipótesis nula, al nivel de significancia del 5%, conclusión que también se obtiene con el intervalo de confianza construido, pues recordemos que si el intervalo de confianza incluye el cero, se puede concluir que hay una diferencia significativa entre las medias.","code":"\nrm(list=ls())\nmetodoA <- c(23.2,26.6,24.4, 23.5, 22.6, 25.7, 25.5, 22.3, \n             22.5, 23.1, 24.6, 25.2, 23.7)\n\nmetodoB <- c(25.7, 27.7, 26.2, 27.9, 25.0, 27.9, 26.1, 25.3, \n             26.2, 27.4, 27.1, 25.8, 26.4, 27.2)\nshapiro.test(metodoA)## \n##  Shapiro-Wilk normality test\n## \n## data:  metodoA\n## W = 0.94428, p-value = 0.5147\nshapiro.test(metodoB)## \n##  Shapiro-Wilk normality test\n## \n## data:  metodoB\n## W = 0.93744, p-value = 0.3866\nvar.test(metodoB,metodoA,alternative= \"two.sided\")## \n##  F test to compare two variances\n## \n## data:  metodoB and metodoA\n## F = 0.49361, num df = 13, denom df = 12, p-value = 0.2212\n## alternative hypothesis: true ratio of variances is not equal to 1\n## 95 percent confidence interval:\n##  0.1523838 1.5564429\n## sample estimates:\n## ratio of variances \n##          0.4936113\nvar.test(metodoA,metodoB,alternative=\"two.sided\")## \n##  F test to compare two variances\n## \n## data:  metodoA and metodoB\n## F = 2.0259, num df = 12, denom df = 13, p-value = 0.2212\n## alternative hypothesis: true ratio of variances is not equal to 1\n## 95 percent confidence interval:\n##  0.6424907 6.5623769\n## sample estimates:\n## ratio of variances \n##           2.025886\nt.test(metodoA, metodoB, alternative = \"two.sided\", var.equal=TRUE)## \n##  Two Sample t-test\n## \n## data:  metodoA and metodoB\n## t = -5.489, df = 25, p-value = 1.058e-05\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -3.431235 -1.558875\n## sample estimates:\n## mean of x mean of y \n##  24.06923  26.56429"},{"path":"análisis-de-varianza-en-una-clasificación.html","id":"análisis-de-varianza-en-una-clasificación","chapter":"Capítulo 8 Análisis de varianza en una clasificación","heading":"Capítulo 8 Análisis de varianza en una clasificación","text":"Para comparar las medias de más de dos grupos, podemos utilizar un ANOVA (Analysis variance). El ANOVA compara las medias de tres o más grupos para determinar si al menos uno de los grupos es significativamente diferente de los demás. Si el ANOVA muestra diferencias significativas, se pueden realizar pruebas post hoc, como la prueba de Tukey, para identificar qué grupos específicos son diferentes entre sí.En el siguiente ejemplo se ilustra el uso de un ANOVA en una clasificación, el cual se utiliza para comparar las medias cuando solo se tiene un factor o variable independiente.Por ejemplo, supongamos que se desea evaluar si la dosis suministrada de un tratamiento produce cambios significativos en el crecimiento de cierta clase de planta, y se cuenta con los siguientes registros, que se asumen independientes:Podemos explorar el comportamiento de la variable altura,y comparar el comportamiento por grupos,Además, podemos resumir la información, representada gráficamente por grupos como sigue,Para evaluar si las varianzas de los distintos grupos son homogéneas, podemos aplicar la prueba de homogeneidad de varianzas de Bartlett, con la siguiente hipótesis nula \\(H_0\\) e hipótesis alternativa \\(H_1\\):\\[ \\begin{matrix}\nH_0:\\sigma_1^2=...=\\sigma_k^2\\\\\nH_1:\\sigma_i^2 \\neq \\sigma_j^2, \\,\\, \\forall \\neq j\n\\end{matrix}\\]Solicitamos R que se aplique la prueba con la siguiente instrucción:Una vez verificado el supuesto de homogeneidad de varianzas, podemos solicitar el análisis de varianza en una clasificación de la siguiente manera:Extraemos ahora los residuales y los analizamos de manera gráfica, verificando su normalidad:o utilizando una prueba cuantil-cuantilo más formalmente, podemos verificar la normalidad de residuales través de una prueba de Shapiro-Wilk:Finalmente, podemos solicitar una prueba post Hoc, como la de Tukey, de la siguiente manera:","code":"\naltura <- c(12.4, 12.8, 12.2, 13, 14, 14.2, 11.6, 15, 12, 13.2, \n            16, 12.6, 14.8, 13, 14, 15, 14, 17, 18, 19, 17.8, 14.4, \n            20, 15.8, 17.0, 20.0, 19.6, 18.0, 20.2, 18.0, 21, 14.8, \n            19.1, 15.8, 18, 20, 21.1, 22, 19, 18.2)\n\ndosis <- c(rep(\"dosis_50\", 10), rep(\"dosis_100\", 10), \n           rep(\"dosis_200\", 10), rep(\"dosis_400\", 10))\n\nrendimiento = data.frame(altura, dosis)\nrendimiento##    altura     dosis\n## 1    12.4  dosis_50\n## 2    12.8  dosis_50\n## 3    12.2  dosis_50\n## 4    13.0  dosis_50\n## 5    14.0  dosis_50\n## 6    14.2  dosis_50\n## 7    11.6  dosis_50\n## 8    15.0  dosis_50\n## 9    12.0  dosis_50\n## 10   13.2  dosis_50\n## 11   16.0 dosis_100\n## 12   12.6 dosis_100\n## 13   14.8 dosis_100\n## 14   13.0 dosis_100\n## 15   14.0 dosis_100\n## 16   15.0 dosis_100\n## 17   14.0 dosis_100\n## 18   17.0 dosis_100\n## 19   18.0 dosis_100\n## 20   19.0 dosis_100\n## 21   17.8 dosis_200\n## 22   14.4 dosis_200\n## 23   20.0 dosis_200\n## 24   15.8 dosis_200\n## 25   17.0 dosis_200\n## 26   20.0 dosis_200\n## 27   19.6 dosis_200\n## 28   18.0 dosis_200\n## 29   20.2 dosis_200\n## 30   18.0 dosis_200\n## 31   21.0 dosis_400\n## 32   14.8 dosis_400\n## 33   19.1 dosis_400\n## 34   15.8 dosis_400\n## 35   18.0 dosis_400\n## 36   20.0 dosis_400\n## 37   21.1 dosis_400\n## 38   22.0 dosis_400\n## 39   19.0 dosis_400\n## 40   18.2 dosis_400\nsummary(altura, data = rendimiento)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   11.60   14.00   15.90   16.34   19.00   22.00\nsummary(altura[dosis == \"dosis_100\"])##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   12.60   14.00   14.90   15.34   16.75   19.00\nsummary(altura[dosis == \"dosis_50\"])##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   11.60   12.25   12.90   13.04   13.80   15.00\nsummary(altura[dosis == \"dosis_200\"])##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   14.40   17.20   18.00   18.08   19.90   20.20\nsummary(altura[dosis == \"dosis_400\"])##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   14.80   18.05   19.05   18.90   20.75   22.00\nboxplot(altura ~ dosis, data = rendimiento)\nbartlett.test(altura ~ dosis, data = rendimiento)## \n##  Bartlett test of homogeneity of variances\n## \n## data:  altura by dosis\n## Bartlett's K-squared = 4.8838, df = 3, p-value = 0.1805\naov.out <- aov(altura ~ dosis, data = rendimiento)\nsummary(aov.out)##             Df Sum Sq Mean Sq F value   Pr(>F)    \n## dosis        3  214.7   71.57   19.35 1.21e-07 ***\n## Residuals   36  133.1    3.70                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\naov_residuals <- aov.out$residuals\nhist(aov_residuals)\nqqnorm(aov_residuals)\nqqline(aov_residuals,col=2)\nshapiro.test(x=aov_residuals)## \n##  Shapiro-Wilk normality test\n## \n## data:  aov_residuals\n## W = 0.98177, p-value = 0.7547\nTukeyHSD(aov.out, conf.level = 0.95)##   Tukey multiple comparisons of means\n##     95% family-wise confidence level\n## \n## Fit: aov(formula = altura ~ dosis, data = rendimiento)\n## \n## $dosis\n##                      diff        lwr         upr     p adj\n## dosis_200-dosis_100  2.74  0.4238594  5.05614056 0.0150760\n## dosis_400-dosis_100  3.56  1.2438594  5.87614056 0.0011022\n## dosis_50-dosis_100  -2.30 -4.6161406  0.01614056 0.0521923\n## dosis_400-dosis_200  0.82 -1.4961406  3.13614056 0.7762839\n## dosis_50-dosis_200  -5.04 -7.3561406 -2.72385944 0.0000062\n## dosis_50-dosis_400  -5.86 -8.1761406 -3.54385944 0.0000003"}]
